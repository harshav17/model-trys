{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langsmith ragas numpy openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name='BaseCamp Q&A', description='Taken from: https://basecamp.com/handbook', data_type=<DataType.kv: 'kv'>, id=UUID('ae36b34b-e912-4273-a7df-a53b4bd8a3af'), created_at=datetime.datetime(2024, 10, 30, 15, 23, 9, 512309, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 10, 30, 15, 23, 9, 512309, tzinfo=datetime.timezone.utc), example_count=0, session_count=0, last_session_start_time=None, inputs_schema=None, outputs_schema=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langsmith\n",
    "\n",
    "client = langsmith.Client()\n",
    "dataset_url = (\n",
    "    \"https://smith.langchain.com/public/56fe54cd-b7d7-4d3b-aaa0-88d7a2d30931/d\"\n",
    ")\n",
    "dataset_name = \"BaseCamp Q&A\"\n",
    "client.clone_public_dataset(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "# Fetch the source documents\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/basecamp-data/basecamp-data.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "with io.BytesIO(response.content) as zipped_file:\n",
    "    with zipfile.ZipFile(zipped_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "docs = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".md\"):\n",
    "        with open(os.path.join(data_dir, filename), \"r\") as file:\n",
    "            docs.append({\"file\": filename, \"content\": file.read()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple InMemory Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "class VectorStoreRetriever:\n",
    "    def __init__(self, docs: list, vectors: list, oai_client):\n",
    "        self._arr = np.array(vectors)\n",
    "        self._docs = docs\n",
    "        self._client = oai_client\n",
    "\n",
    "    @classmethod\n",
    "    async def from_docs(cls, docs, oai_client):\n",
    "        embeddings = await oai_client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[doc[\"content\"] for doc in docs]\n",
    "        )\n",
    "        vectors = [emb.embedding for emb in embeddings.data]\n",
    "        return cls(docs, vectors, oai_client)\n",
    "\n",
    "    @traceable\n",
    "    async def query(self, query: str, k: int = 5) -> List[dict]:\n",
    "        embed = await self._client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[query]\n",
    "        )\n",
    "        # \"@\" is just a matrix multiplication in python\n",
    "        scores = np.array(embed.data[0].embedding) @ self._arr.T\n",
    "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
    "        return [\n",
    "            {**self._docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "\n",
    "class NaiveRagBot:\n",
    "    def __init__(self, retriever, model: str = \"gpt-4-turbo-preview\"):\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        # and is completely optional\n",
    "        self._client = wrap_openai(openai.AsyncClient())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable\n",
    "    async def get_answer(self, question: str):\n",
    "        similar = await self._retriever.query(question)\n",
    "        response = await self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful AI assistant.\"\n",
    "                    \" Use the following docs to help answer the user's question.\\n\\n\"\n",
    "                    f\"## Docs\\n\\n{similar}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # The RAGAS evaluators expect the \"answer\" and \"contexts\"\n",
    "        # keys to work properly. If your pipeline does not return these values,\n",
    "        # you should wrap in a function that provides them.\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in similar],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = await VectorStoreRetriever.from_docs(docs, openai.AsyncClient())\n",
    "rag_bot = NaiveRagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You get several types of time off at 37signals, including:\\n\\n### Paid Time Off (PTO)\\n- **Vacation Time:** 37signals offers 18 days of paid time off plu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await rag_bot.get_answer(\"How much time off do we get?\")\n",
    "response[\"answer\"][:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from nltk) (4.66.6)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk) (2024.9.11)\n",
      "Installing collected packages: joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "from ragas.metrics import (\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    ")\n",
    "\n",
    "# Wrap the RAGAS metrics to use in LangChain\n",
    "evaluators = [\n",
    "    EvaluatorChain(metric)\n",
    "    for metric in [\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "    ]\n",
    "]\n",
    "eval_config = RunEvalConfig(custom_evaluators=evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'extraneous-window-46' at:\n",
      "https://smith.langchain.com/o/bc1abc05-6850-4a1a-8627-3b31ec53e09f/datasets/ae36b34b-e912-4273-a7df-a53b4bd8a3af/compare?selectedSessions=c45a0371-8bc6-4755-a027-9a4fe4cf80b3\n",
      "\n",
      "View all tests for Dataset BaseCamp Q&A at:\n",
      "https://smith.langchain.com/o/bc1abc05-6850-4a1a-8627-3b31ec53e09f/datasets/ae36b34b-e912-4273-a7df-a53b4bd8a3af\n",
      "[>                                                 ] 0/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 770493b4-8d2b-4a52-8c84-4e3b6af1ebc3 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_1'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_1'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_1'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[->                                                ] 1/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 03862567-77d7-4567-b7b4-9829d817d6a7 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_4'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---->                                             ] 2/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 2b08b034-8357-44ac-8877-9bd2df1fec47 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_4'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------>                                           ] 3/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run d2f3b176-dce3-4014-a1b6-5c4c1f4cc801 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_3'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------->                                        ] 4/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 88ee998e-4fd9-42f8-9a95-24ea20e45420 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_0'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_0'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_0'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------->                                      ] 5/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run eb35e359-34f3-4cca-87b9-7bf380dca89b with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_2'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------->                                 ] 7/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run d8c5f8cf-801e-425f-9ffe-ba31f8447167 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_3'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Error evaluating run f8ca95cd-3342-4115-81c8-09e41cda97cb with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_1'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_1'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_1'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------>                               ] 8/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 8ac5f014-3480-45e7-9e29-7975dd4f502d with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_3'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------->                             ] 9/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 1ebc2c4d-54bc-414c-a5a3-62cdb7b05c9e with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_3'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------->                          ] 10/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run b89696eb-5552-4a7a-8630-ae715203f8ea with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_4'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------->                        ] 11/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run d5e1fc56-3ec1-46ca-afc5-68fea9b2626e with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_4'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------------------->                     ] 12/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run ee40f3e0-459e-4c8f-9fe4-fdb8badfdb1c with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_4'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------>                   ] 13/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 02f97afb-a29e-460a-a1df-ba1e7e7625b8 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_4'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_4'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------------------->                 ] 14/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 2936ce7d-e79d-4c1b-9c6f-846cbd8df7d1 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_3'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------->            ] 16/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 98fa0a53-2239-4fdc-9df9-8f536df77a8c with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_3'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_3'.\")\n",
      "Error evaluating run 5f147cb5-71ec-4bbd-890a-f4de06e51863 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_2'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------->          ] 17/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 1ad37d26-ef3c-41ba-b724-8cddf8fa9724 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_2'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------>       ] 18/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 91938ed4-e9d8-4357-b3b1-731531f347be with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_2'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------------------------------->     ] 19/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 2b0c2fe1-8d26-44b7-8f13-246041e72194 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_2'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------------------------->  ] 20/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run aa5d7e42-0313-483c-aa8f-541ad6cf8409 with EvaluatorChain: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 128, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 253, in single_turn_score\n",
      "    raise e\n",
      "  File \"/Users/harsha/workspace/pgnd-ai/model-trys/.venv/lib/python3.10/site-packages/ragas/metrics/base.py\", line 246, in single_turn_score\n",
      "    loop = asyncio.get_event_loop()\n",
      "  File \"/Users/harsha/.pyenv/versions/3.10.11/lib/python3.10/asyncio/events.py\", line 656, in get_event_loop\n",
      "    raise RuntimeError('There is no current event loop in thread %r.'\n",
      "RuntimeError: There is no current event loop in thread 'asyncio_2'.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: RuntimeError(\"There is no current event loop in thread 'asyncio_2'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 21/21"
     ]
    }
   ],
   "source": [
    "results = await client.arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=rag_bot.get_answer,\n",
    "    evaluation=eval_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
